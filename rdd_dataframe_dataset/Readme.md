# RDD/Dataframe/Dataset

Аналитическая витрина на основе сырых данных, используя Spark

## Цель:
Выполнив домашнее задание Вы получите опыт работы с RDD API, DataFrame API,Dataset API. Научитесь строить аналитическую витрину на основе сырых данных, используя Spark и различные API.
https://github.com/vadopolski/otus-hadoop-homework.git

## ДЗ предварительная инструкция

* Скачать и установить Idea Community - https://www.jetbrains.com/idea/download/#section=windows
* Установить плагин Скала
* Скачать и установить Java JDK 11 - https://www.oracle.com/java/technologies/javase-jdk11-downloads.html
* Скачать и установить git - https://git-scm.com/downloads
* Скачать и установить локально дистрибутив Hadoop (инструкция для Windows - https://www.datasciencecentral.com/profiles/blogs/how-to-install-and-run-hadoop-on-windows-for-beginners )
* Скачать стартовый проект с Гитхаб c помощью команды git clone https://github.com/vadopolski/otus-hadoop-homework
* Запустить Idea и открыть скаченный проект File -> Open -> project folder/build.sbt
* Открыть в проекте файл src/main/scala/homework2/DataApiHomeWorkTaxi.scala запустить его, `Ctrl + Shift10`
* Скачать и установить docker-compose
* Из корневой папки проекта запустить сделать запуск - docker-compose up

## ДЗ основная инструкция и задания к занятию по Spark Data API:

### Основная инструкция задание 1:
Загрузить данные в первый DataFrame из файла с фактическими данными поездок в Parquet (src/main/resources/data/yellow_taxi_jan_25_2018). Загрузить данные во второй DataFrame из файла со справочными данными поездок в csv (src/main/resources/data/taxi_zones.csv) С помощью DSL построить таблицу, которая покажет какие районы самые популярные для заказов. Результат вывести на экран и записать в файл Паркет.

**Результат:**

В консоли должны появиться данные с результирующей таблицей, в файловой системе должен появиться файл. Решение оформить в github gist.
https://gist.github.com/andreyc2018/e991aac350419ab464db5d7a51c6dd57

### Основная инструкция задание 2:
Загрузить данные в RDD из файла с фактическими данными поездок в Parquet (src/main/resources/data/yellow_taxi_jan_25_2018). С помощью lambda построить таблицу, которая покажет В какое время происходит больше всего вызовов. Результат вывести на экран и в txt файл c пробелами.

**Результат:**

В консоли должны появиться данные с результирующей таблицей, в файловой системе должен появиться файл. Решение оформить в github gist.
https://gist.github.com/andreyc2018/66896818030eb298bd42e9b5226d93e6

### Основная инструкция задание 3:
Загрузить данные в DataSet из файла с фактическими данными поездок в Parquet (src/main/resources/data/yellow_taxi_jan_25_2018). С помощью DSL и lambda построить таблицу, которая покажет. Как происходит распределение поездок по дистанции? Результат вывести на экран и записать в бд Постгрес (докер в проекте). Для записи в базу данных необходимо продумать и также приложить инит sql файл со структурой.

_(Пример: можно построить витрину со следующими колонками: общее количество поездок, среднее расстояние, среднеквадратическое отклонение, минимальное и максимальное расстояние)_

**Результат:**

В консоли должны появиться данные с результирующей таблицей, в бд должна появиться таблица. Решение оформить в github gist.
https://gist.github.com/andreyc2018/143b6445d943309057e5ffa01623d805

